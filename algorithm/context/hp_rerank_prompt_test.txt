Given a dataset with the following properties:

1. Columns: age	sex	cp	trestbps	chol	fbs	restecg	thalach	exang	oldpeak	slope	ca	thal	target
2. Statistics:
The dataset has the following characteristics:

Data Type: The overall data type is Mixture.

The sample size is 1025 with 14 features. This dataset is not time-series data. 

Data Quality: There are no missing values in the dataset.

Statistical Properties:
- Linearity: The relationships between variables are not predominantly linear.
- Gaussian Errors: The errors in the data do not follow a Gaussian distribution.
- Heterogeneity: The dataset is not heterogeneous. 





We have selected the following algorithm for causal discovery:

Algorithm: PC
Description: PC is a constraint-based causal discovery algorithm that utilizes conditional independence tests, generating a Completed Partially Directed Acyclic Graph (CPDAG).
The PC algorithm balances the need for handling non-linear relationships with efficient computation, especially given the constraints (non-GPU system and one-minute run time). It also provides a full causal graph output rather than just local dependency structures.

Now, we need to set up the primary hyperparameters for this algorithm. Please consider the dataset characteristics and the algorithm requirements to suggest appropriate values for the following hyperparameters:

[PRIMARY_HYPERPARAMETERS]

For each primary hyperparameter, provide:
1. The full name of the hyperparameter that is aligned with your understanding ('independence test', 'max depth', 'score function', etc.)
2. The suggested value
3. A brief explanation of why this value is appropriate given the dataset characteristics and algorithm requirements
4. Each primary hyperparameter is provided with a default value, which should be adjusted based on the dataset characteristics and algorithm requirements
5. For time-series data, give a higher priority to the statistically estimated lag order provided under the Statistics section.

Here is the CUDA/GPU availability to help you decide hyperparameters:


Current machine doesn't support CUDA, do not choose any GPU-powered algorithms.

Actively use and reason with the following information about each hyperparameter to inform your decisions:

"{\n  \"algorithm_name\": \"PC\",\n  \"alpha\": {\n    \"meaning\": \"Desired significance level in (0, 1)\",\n    \"available_values\": {\n      \"default\": 0.05,\n      \"small_sample\": 0.1,\n      \"large_sample\": 0.01\n    },\n    \"expert_suggestion\": \"Adjust based on sample size, more conservative (lower) values for larger samples. If < 500, use 0.1; Else if 500-10000 (<10000 but >500), use 0.05; Else if > 10000, using 0.01.\"\n  },\n  \"indep_test\": {\n    \"meaning\": \"Independence test method\",\n    \"available_values\": {\n      \"default\": \"fisherz_cpu\",\n      \"continuous_cpu\": \"fisherz_cpu\",\n      \"continuous_gpu\": \"fisherz_gpu\",\n      \"discrete_cpu\": \"chisq_cpu\",\n      \"discrete_gpu\": \"chisq_gpu\",\n      \"robust_nonlinear_cpu\": \"kci_cpu\",\n      \"robust_nonlinear_gpu\": \"cmiknn_gpu\",\n      \"fast_robust_nonlinear_cpu\": \"fastkci_cpu\",\n      \"approximate_fast_nonlinear_cpu\": \"rcit_cpu\"\n    },\n    \"expert_suggestion\": \"Choose based on data type and hardware. CPU TESTS: 'fisherz_cpu' for linear continuous data; 'chisq_cpu' for discrete data (only applied for pure discrete data); 'kci_cpu' for nonlinear data (very slow, use only with variable size < 15 and sample size < 1500); 'fastkci_cpu' is faster than kci (use with < 20 variables and sample size < 3000); 'rcit_cpu' is the fastest approximation of kci (use with < 30 variables and sample size < 5000). GPU TESTS: 'fisherz_gpu' and 'chisq_gpu' (only applied for pure discrete data) work similarly but are extremely fast because of GPU's super parallel computing; 'cmiknn_gpu' is a GPU-accelerated nonparametric test that provides 1000x speedup compared to CPU-based 'kci' with comparable accuracy. GPU acceleration is strongly recommended for large datasets.\"\n  },\n  \"depth\": {\n    \"meaning\": \"Maximum depth for skeleton search\",\n    \"available_values\": {\n      \"default\": -1,\n      \"small_graph\": 6,\n      \"medium_graph\": 4,\n      \"large_graph\": 2,\n      \"extra_large_graph\": 1\n    },\n    \"expert_suggestion\": \"Use -1 for unlimited depth. For large graphs, limiting depth (e.g., 1-3) can significantly speed up the algorithm at the cost of some accuracy. A graph with node number < 10, use depth 6; A graph with node number 10 - 25, use depth 4; A graph with node number 25-50, use depth 2; A graph with node number > 50, use depth 1.\"\n  }\n}"

Please provide your suggestions in a structured JSON format. Your response should look like this:

{
  "algorithm": "PC",
  "hyperparameters": {
    "[HYPERPARAMETER_1_NAME]": {
      "full_name": "[HYPERPARAMETER_1_FULL_NAME]",
      "value": [SUGGESTED_VALUE],
      "explanation": "[BRIEF_EXPLANATION]"
    },
    "[HYPERPARAMETER_2_NAME]": {
      "full_name": "[HYPERPARAMETER_2_FULL_NAME]",
      "value": [SUGGESTED_VALUE],
      "explanation": "[BRIEF_EXPLANATION]"
    },
    ...
  }
}

Please always determine the hyperparameters from its corresponding "Suggested Values" part, DO NOT use any values just exist in other context but not in "Suggested Values".

Please consider the trade-offs between accuracy and computational efficiency when suggesting values. If you're unsure about a specific value, you may suggest using the default value and explain why.

Please consider using the estimated time lag value. If you think a different value might be useful for the given context, you may suggest the value and explain why it will be better.

Please provide your hyperparameter suggestions following this JSON structure.
