You will conduct causal discovery on the Tabular Dataset ./demo_data/20250329_100726/house_price/house_price.csv containing the following Columns:

Id	MSSubClass	MSZoning	LotFrontage	LotArea	Street	LotShape	LandContour	Utilities	LotConfig	LandSlope	Neighborhood	Condition1	Condition2	BldgType	HouseStyle	OverallQual	OverallCond	YearBuilt	YearRemodAdd	RoofStyle	RoofMatl	Exterior1st	Exterior2nd	MasVnrArea	ExterQual	ExterCond	Foundation	BsmtQual	BsmtCond	BsmtExposure	BsmtFinType1	BsmtFinSF1	BsmtFinType2	BsmtFinSF2	BsmtUnfSF	TotalBsmtSF	Heating	HeatingQC	CentralAir	Electrical	1stFlrSF	2ndFlrSF	LowQualFinSF	GrLivArea	BsmtFullBath	BsmtHalfBath	FullBath	HalfBath	BedroomAbvGr	KitchenAbvGr	KitchenQual	TotRmsAbvGrd	Functional	Fireplaces	GarageType	GarageYrBlt	GarageFinish	GarageCars	GarageArea	GarageQual	GarageCond	PavedDrive	WoodDeckSF	OpenPorchSF	EnclosedPorch	3SsnPorch	ScreenPorch	PoolArea	MiscVal	MoSold	SaleType	SaleCondition	SalePrice	domain_index

The Detailed Background Information is listed below:

This is fake domain knowledge for debugging purposes.

The Statistics Information about the dataset is:

The dataset has the following characteristics:

Data Type: The overall data type is Mixture.

The sample size is 1460 with 74 features. This dataset is not time-series data. 

Data Quality: There are missing values in the dataset.

Statistical Properties:
- Linearity: The relationships between variables are not predominantly linear.
- Gaussian Errors: The errors in the data do not follow a Gaussian distribution.
- Heterogeneity: The dataset is heterogeneous. 

- Domain Index: YrSold

Based on the above information, please select the best-suited algorithm from the following candidate (the order of the algorithm candidates is not important):

dict_keys(['CDNOD', 'InterIAMB', 'IAMBnPC'])

===============================================
Note that the user can only wait for 1440.0 minutes for the algorithm execution, please ensure the time cost of the selected algorithm would not exceed it!
The estimated time costs of the following algorithms using linear estimation methods (e.g. Fisherz for constraint-based methods, BIC for score-based methods) are below. Use it as a reference for the algorithm runtime comparison, note that the absolute value might changes significantly when the estimation methods are not linear (e.g. KCI for constraint-based methods, Generalized score for score-based methods). Consider the time cost wisely when selecting the algorithm, it is critical but less important than the performance when the time cost does not exceed the waiting time. As long as the timecost difference is not that large 1440.0, you should pivot more on the performance.

CDNOD: 1.5 minutes
InterIAMB: 7.5 minutes
IAMBnPC: 9.2 minutes

At the same time, be careful about the current device availability for GPU/CUDA acceleration. Note that some algorithm settings would need GPU to run, which could be a indirect limitation on the algorithm application potential:


Current machine doesn't support CUDA, do not choose any GPU-powered algorithms.

===============================================
Detailed Profiles of the algorithm candidates are shown here. We also include the supported hyperparamerters as additional information to help you know the potentials of each algorithm combining various hyperparamerter settings. You MUST actively combine and reason with them:

======================================

# CDNOD

Below is a structured profile of the CDNOD (Constraint-based causal Discovery from Nonstationary or heterogeneous Data) algorithm, following the seven dimensions specified in the meta-prompt. The information presented integrates the provided hyperparameter settings, benchmarking results, and external knowledge. 

────────────────────────────────────────────────────────────
1. Hyper-Parameters Sensitivity
────────────────────────────────────────────────────────────

• Number of Key Hyperparameters  
  - CDNOD's primary hyperparameters include:  
    1. α (alpha): The significance level for conditional independence tests.  
    2. indep_test: The choice of independence test (e.g., "fisherz_cpu", "fisherz_gpu", "chisq_cpu", "chisq_gpu", "cmiknn_gpu", etc.).  
    3. depth: The maximum depth in the skeleton discovery phase.  
  - These three hyperparameters—alpha, indep_test, and depth—are generally the most influential in determining both the algorithm's accuracy and runtime.

• Tuning Difficulty  
  - Default settings are typically sufficient for many domains (e.g., alpha=0.05, indep_test="fisherz_cpu", depth=-1). However, the selected values can significantly affect performance when sample sizes or graph sizes are extreme.  
  - The guidelines for alpha (e.g., 0.1 for <500 samples, 0.05 for mid-range, 0.01 for very large samples) offer straightforward, data-driven rules. This means domain experts or automated routines can tune alpha more reliably given the sample size.  
  - For the independence test, recommended defaults exist depending on data type. GPU-accelerated tests are now available, providing significant performance improvements: "fisherz_gpu" for continuous data, "chisq_gpu" for discrete data, and "cmiknn_gpu" for nonparametric testing with GPU acceleration.

• Sensitivity  
  - Alpha exerts a substantial influence on the graph's sparsity: smaller alpha yields sparser graphs, reducing false positives but potentially missing weaker edges. Larger alpha leads to denser graphs, possibly increasing false positives.  
  - Depth affects the thoroughness of the skeleton search. A high (or unlimited) depth can improve accuracy on complex graphs but may sharply increase runtime. Lower depth settings speed up computations while potentially missing longer-range conditional dependencies.
  - Switching from CPU to GPU implementations (e.g., from "fisherz_cpu" to "fisherz_gpu") can dramatically improve runtime without affecting accuracy, making CDNOD much more practical for large datasets.

• Critique/Extension  
  - Hyperparameters controlling the search complexity (e.g., depth) most strongly influence runtime and can also affect correctness if restricted too aggressively.  
  - Hyperparameters tied to statistical tests (alpha, indep_test) have a more direct effect on false positives/negatives. In practice, balancing both sets of parameters is essential for robust performance.
  - The GPU-accelerated tests provide extreme speedups compared to their CPU counterparts, especially for large datasets, addressing one of the traditional limitations of constraint-based methods.

────────────────────────────────────────────────────────────
2. Robustness & Scalability
────────────────────────────────────────────────────────────

• Tolerance to Bad Data Quality  
  - Missing Data: CDNOD is not natively specialized in sophisticated imputation, but it can accommodate partial missingness if the user or a preprocessing routine properly handles or imputes missing entries. The benchmarking results suggest it performs very well overall in missing-data scenarios (ranking near the top in that category).  
  - Measurement/Observation Error: Benchmarks also indicate strong tolerance to moderate or even severe noise, placing CDNOD among the more robust methods tested in handling measurement error.

• Tolerance to Sparse/Dense Connected Systems  
  - While not extensively detailed in the provided reports, constraint-based methods typically show stable performance on sparse networks. Dense networks can still be handled, but the computational load and potential for spurious edges may grow. Depth constraints can partially mitigate these issues.

• Scalability  
  - With the integration of GPU-accelerated independence tests ('fisherz_gpu', 'chisq_gpu', and 'cmiknn_gpu'), CDNOD's scalability has significantly improved. The GPU tests provide extreme speedups compared to their CPU counterparts, especially for large datasets.
  - According to the hyperparameter information, 'cmiknn_gpu' offers a 1000x speedup compared to CPU-based 'kci' with comparable accuracy, making nonparametric testing viable for much larger datasets.
  - Even with GPU acceleration, restricting depth remains an important strategy for very large graphs to manage computational complexity.

• Critique/Extension  
  - Parallelization: Constraint-based methods (including CDNOD) can often be parallelized by splitting conditional independence tests across computing cores. The GPU-accelerated tests take this to another level, providing massive parallelization on GPU hardware.
  - Approximation options like restricting the skeleton search depth or using GPU-accelerated tests strike an excellent balance between runtime and accuracy, making CDNOD much more competitive for large-scale applications.

────────────────────────────────────────────────────────────
3. Mixed Data & Complex Functions
────────────────────────────────────────────────────────────

• Noise Type  
  - CDNOD does not assume strictly Gaussian noise. It supports a variety of independence tests (including kernel-based nonparametric methods), making it suitable for non-Gaussian scenarios.
  - The GPU-accelerated 'cmiknn_gpu' test provides a powerful nonparametric option that can handle complex noise distributions with significantly improved performance.

• Mixed Data (Continuous & Discrete)  
  - CDNOD can integrate different conditional independence tests: 'fisherz_cpu'/'fisherz_gpu' for continuous variables; 'chisq_cpu'/'chisq_gpu' for discrete; or a mix for hybrid data.
  - Both CPU and GPU implementations are available for different data types, allowing for efficient processing regardless of data characteristics.

• Heterogeneous Data  
  - CDNOD is specifically designed to address nonstationary and heterogeneous conditions, which is one of its defining strengths (confirmed by top performance in the "Heterogeneity" category of the provided benchmarks).
  - The GPU-accelerated tests make it much more practical to apply CDNOD to large heterogeneous datasets that would be computationally prohibitive with CPU-only implementations.

• Complex Functional Forms  
  - When the relationships between variables are nonlinear, the 'cmiknn_gpu' test provides an excellent option for capturing complex dependencies with dramatically improved performance compared to CPU-based nonparametric tests.
  - The 1000x speedup of 'cmiknn_gpu' compared to 'kci' makes nonparametric testing practical for much larger datasets, allowing CDNOD to handle complex functional forms at scale.

• Critique/Extension  
  - If users initially rely on purely linear tests (e.g., "fisherz_cpu" or "fisherz_gpu") for data that are strongly nonlinear, they risk underspecifying relationships. Therefore, domain knowledge or preliminary data checks can guide the choice of a more robust independence test like 'cmiknn_gpu'.
  - Overfitting can occur if alpha is set too high while a flexible, nonlinear test is used. Proper emphasis on cross-validation or domain-driven alpha choices is advisable.

────────────────────────────────────────────────────────────
4. Computational Complexity
────────────────────────────────────────────────────────────

• Theoretical Time Complexity  
  - As a constraint-based algorithm, skeleton discovery and orientation typically have a complexity that grows with both the number of variables and the maximum conditioning set size. A simplified notation for the worst-case complexity can be denoted as:  
    O(p^k)  
  where p is the number of variables and k depends on the search depth. Exact exponents vary based on independence test complexity and data sample size.

• Variability in Practical Usage  
  - If depth is set to -1 (unlimited), the search can become computationally heavy for large graphs. Reducing it to smaller values (e.g., 1–3) often substantially cuts runtime.  
  - Selecting GPU-accelerated tests ('fisherz_gpu', 'chisq_gpu', 'cmiknn_gpu') provides dramatic efficiency gains with no trade-offs in accuracy, making CDNOD much more practical for large-scale applications.
  - The 'cmiknn_gpu' test in particular offers a 1000x speedup compared to CPU-based 'kci', making nonparametric testing viable for much larger datasets.

• Critique/Extension  
  - In real-world datasets with many variables, worst-case complexity can be mitigatingly high, but typical performance can be significantly better when the underlying network is not extremely dense.  
  - The GPU-accelerated tests provide massive parallelization, dramatically reducing the practical runtime for large datasets and making CDNOD much more competitive for large-scale applications.

────────────────────────────────────────────────────────────
5. Interpretability
────────────────────────────────────────────────────────────

• Output Format  
  - CDNOD typically produces a directed acyclic graph (DAG) or partially directed graph (CPDAG) representing causal structures. It may also provide adjacency matrices and edge confidence scores, depending on the implementation.

• Strength of the Output Format  
  - Graphical outputs are straightforward for users to interpret, with edges representing putative causal directions. Some implementations offer p-values or confidence measures that accompany edge findings.

• Limitations of the Output Format  
  - Like most constraint-based methods, certain edges can remain unoriented if the data are insufficient or if the relevant conditional independence tests are ambiguous.  
  - The underlying changing distribution (nonstationarity) can sometimes complicate orientation, leading to partial orientation in complex scenarios.

• Critique/Extension  
  - Domain experts often refine or prune orientations after the algorithm's initial output. In contexts like multi-stage or time-varying processes, additional domain knowledge can greatly enhance interpretability.
  - The improved scalability from GPU-accelerated tests allows CDNOD to be applied to larger, more complex datasets, potentially yielding more comprehensive and informative causal graphs.

────────────────────────────────────────────────────────────
6. Assumptions
────────────────────────────────────────────────────────────

• Critical Assumptions  
  - Markov and Faithfulness: Variables follow standard causal discovery assumptions that d-separations correspond to conditional independencies.  
  - Causal Sufficiency (with a twist): CDNOD assumes no unobserved confounders that cannot be partly captured by domain indicators or time indices in nonstationary settings.  
  - Nonstationarity/Heterogeneity: CDNOD leverages changes in distribution to help identify causal directions.

• Violation Impact  
  - If truly hidden confounders exist that are unrelated to domain/time indicators, performance may degrade or lead to incorrect orientations.  
  - If the data deviate heavily from the faithfulness assumption, false positives or false negatives can increase in the learned graph.

• Critique/Extension  
  - Extensions of CDNOD can handle partially missing or ambiguous domain indices.  
  - In practice, moderate violations of the assumptions (e.g., mild confounding) might still yield useful causal insights, but caution is warranted.
  - The availability of GPU-accelerated nonparametric tests like 'cmiknn_gpu' makes it more practical to apply CDNOD to complex datasets where linear assumptions may not hold.

────────────────────────────────────────────────────────────
7. (Optional) Real-World Benchmarks
────────────────────────────────────────────────────────────

• Performance on Real Datasets  
  - According to some demonstrations (e.g., financial market data applications), CDNOD performs successfully in capturing dynamic causal structures underlying changing market conditions.  
  - Benchmarks indicate it is among the stronger algorithms in contexts involving noise, measurement error, and missing data. In those areas, CDNOD scored near the top in overall performance.
  - The integration of GPU-accelerated tests makes CDNOD much more practical for large real-world datasets that would be computationally prohibitive with CPU-only implementations.

• Practical Tips  
  - For large sample sizes (>10,000), use a lower alpha (e.g., α=0.01) and consider a smaller depth to control runtime.  
  - If data are suspected of containing strongly nonlinear relationships, opt for the GPU-accelerated 'cmiknn_gpu' test, which provides a 1000x speedup compared to CPU-based 'kci' with comparable accuracy.
  - For large datasets, always use the GPU-accelerated tests ('fisherz_gpu', 'chisq_gpu', 'cmiknn_gpu') when GPU hardware is available, as they provide extreme speedups with no loss in accuracy.
  - Domain-driven insights can help refine or interpret partially oriented edges, especially in real-world settings like finance, biology, or social sciences.

────────────────────────────────────────────────────────────
Summary
────────────────────────────────────────────────────────────

CDNOD is specifically designed for causal discovery in nonstationary and heterogeneous data. Its ability to handle various data types (continuous, discrete, mixed), along with flexible independence test choices, makes it adaptable across multiple domains. With the integration of GPU-accelerated tests ('fisherz_gpu', 'chisq_gpu', and 'cmiknn_gpu'), its scalability has significantly improved, making it much more practical for large datasets. The 'cmiknn_gpu' test in particular provides a 1000x speedup for nonparametric testing compared to CPU-based alternatives, making CDNOD much more competitive for complex, non-linear causal discovery tasks. As with most constraint-based methods, interpretability is straightforward in graph form, though some edges may remain unoriented without further domain knowledge. Its robust performance in the face of measurement error, missing data, and heterogeneous sources underscores its value for complex real-world applications where distributions shift across time or other conditions.

────────────────────────────────────────────────────────
Benchmarking Results
────────────────────────────────────────────────────────

• Comparative Performance
  – The benchmarking compared 19 different causal discovery algorithms across multiple scenarios.
  – Each algorithm was evaluated on performance (accuracy), efficiency (runtime), and composite metrics, which are represented as level scores from 1-5, with 5 being the best.
  – Levels scores of composite metrics combine performance and efficiency (weights: 0.8 and 0.2 respectively).
[NOTE] The ranking is smaller, the better. The level score is higher, the better.

• Algorithm Rankings

| Scenario | Rank (Mean) | Rank (Std Dev) | Performance (Level) | Efficiency (Level) | Composite (Level) |
|----------|-----------|---------|-------------|------------|------------|
| Scalability | 9.4 | 2.29 | 2.0 | 5.0 | 3.0 |
| Heterogeneity | 9.5 | 1.50 | 2.0 | 4.0 | 2.0 |
| Measurement Error | 11.0 | 0.00 | 3.0 | 4.0 | 2.0 |
| Noise Type | 13.0 | 2.00 | 1.0 | 4.0 | 2.0 |
| Missing Data | 9.2 | 1.79 | 2.0 | 5.0 | 2.0 |
| Edge Probability | 10.0 | 0.82 | 3.0 | 4.0 | 3.0 |
| Discrete Ratio | 10.7 | 1.25 | 2.0 | 4.0 | 2.0 |

• Analysis

  – Overall mean ranking across 7 scenarios: 10.40
  – Average standard deviation: 1.38


## Supported hyperparameters: {
    "algorithm_name": "CDNOD",
    "alpha": {
        "meaning": "Significance level in (0, 1)",
        "available_values": {
            "default": 0.05,
            "small_sample": 0.1,
            "large_sample": 0.01
        },
        "expert_suggestion": "Adjust based on sample size, more conservative (lower) values for larger samples. If < 500, use 0.1; Else if 500-10000 (<10000 but >500), use 0.05; Else if > 10000, using 0.01."
    },
    "indep_test": {
        "meaning": "Independence test method",
        "available_values": {
            "default": "fisherz_cpu",
            "continuous_cpu": "fisherz_cpu",
            "continuous_gpu": "fisherz_gpu",
            "discrete_cpu": "chisq_cpu",
            "discrete_gpu": "chisq_gpu",
            "robust_nonlinear_cpu": "kci_cpu",
            "robust_nonlinear_gpu": "cmiknn_gpu",
            "fast_robust_nonlinear_cpu": "fastkci_cpu",
            "approximate_fast_nonlinear_cpu": "rcit_cpu"
        },
        "expert_suggestion": "Choose based on data type and hardware. CPU TESTS: 'fisherz_cpu' for linear continuous data; 'chisq_cpu' for discrete data (only applied for pure discrete data); 'kci_cpu' for nonlinear data (very slow, use only with variable size < 15 and sample size < 1500); 'fastkci_cpu' is faster than kci (use with < 20 variables and sample size < 3000); 'rcit_cpu' is the fastest approximation of kci (use with < 30 variables and sample size < 5000). GPU TESTS: 'fisherz_gpu' and 'chisq_gpu' (only applied for pure discrete data) work similarly but are extremely fast because of GPU's super parallel computing; 'cmiknn_gpu' is a GPU-accelerated nonparametric test that provides 1000x speedup compared to CPU-based 'kci' with comparable accuracy. GPU acceleration is strongly recommended for large datasets."
    },
    "depth": {
        "meaning": "Maximum depth for skeleton search",
        "available_values": {
            "default": -1,
            "small_graph": 6,
            "medium_graph": 4,
            "large_graph": 2,
            "extra_large_graph": 1
        },
        "expert_suggestion": "Use -1 for unlimited depth. For large graphs, limiting depth (e.g., 1-3) can significantly speed up the algorithm at the cost of some accuracy. A graph with node number < 10, use depth 6; A graph with node number 10 - 25, use depth 4; A graph with node number 25-50, use depth 2; A graph with node number > 50, use depth 1."
    }
}

======================================

# InterIAMB

Below is an in-depth profile of InterIAMB, organized around the seven dimensions (or “degrees”) specified in the meta-prompt. The following draws on the provided hyperparameter definitions, the comparative benchmarking results, external online information about InterIAMB, and general knowledge of Markov blanket (MB) and causal discovery methods.

────────────────────────────────────────────────────────
1. Hyper-Parameters Sensitivity
────────────────────────────────────────────────────────

• Number of Key Hyperparameters  
  InterIAMB’s foundational hyperparameter is the alpha (α) significance level for conditional independence testing. In practice, there are also choices of which independence test (fisherz, chisq, etc.) to use, but α is by far the most impactful parameter guiding the algorithm. Hence, we can consider two main critical hyperparameters for InterIAMB:  
  1) alpha (the significance threshold).  
  2) indep_test (choice of independence test).  

• Tuning Difficulty  
  – Alpha: Default guidance is straightforward. For small samples (<500), a higher alpha (e.g., 0.1) is often suggested to avoid missing significant edges. For moderate sample sizes (500–10,000), α = 0.05 is a common setting. For very large datasets (>10,000), α = 0.01 is recommended to reduce false positives.  
  – Independence Test: The algorithm offers recommended defaults (e.g., “fisherz” for continuous data, “chisq” for discrete, “gsq” for simpler mixed data). These guidelines limit the tuning difficulty because the user can often select the test based on data type.  

• Sensitivity  
  – Alpha: Small changes to α can shift how many conditional independencies are declared. Lower α typically yields a more conservative MB, with fewer false positives but potentially more false negatives. Higher α can speed up execution slightly (fewer re-checks needed), but can also add spurious edges.  
  – Independence Test Choice: Selecting a more advanced non-linear test (e.g., “kci” or “fastkci”) can improve detection of complex relationships but typically increases computation.  

• Critique/Extension  
  – For InterIAMB, most of the effect is from parameters controlling the significance testing step (especially α), rather than from search complexity parameters (it follows an iterative MB strategy). Thus, adjustments in significance threshold often dominate performance changes in practice.  

────────────────────────────────────────────────────────
2. Robustness & Scalability
────────────────────────────────────────────────────────

• Tolerance to Bad Data Quality  
  – Missing Data: Benchmarks suggest InterIAMB is not particularly robust when data are missing at random in large portions, indicating a drop in performance and efficiency compared to scenarios without missing data. Handling missingness usually requires either imputation or specialized independence tests, neither of which is a built-in feature of the standard InterIAMB formulation.  
  – Measurement/Observation Error: In the presence of moderate noise or errors, InterIAMB tends to remain fairly stable, but severe measurement error can compromise the correctness of the conditional independence checks—leading to more false edges or missing edges in the identified MB.  

• Tolerance to Sparse/Dense Connected Systems  
  – Overall, InterIAMB’s performance is typically quite solid for moderately dense networks. For highly sparse networks, it can sometimes require carefully tuning α since the algorithm might be overly conservative and fail to detect weaker associations. Conversely, in highly dense networks, the iterative MB approach can become more computationally expensive as more variables must be checked for conditional independence.  

• Scalability  
  – Sample Size: InterIAMB can process thousands of samples efficiently, particularly with optimized independence tests. However, extremely large sample sizes (>10,000) often warrant a stricter α to limit false positives.  
  – Number of Variables: InterIAMB improves on the original IAMB, but can still encounter computational bottlenecks with very high-dimensional data. Some parallelized or optimized implementations exist, which help scale to larger variable sets by parallel independence testing.  

• Critique/Extension  
  – Parallelization: Because InterIAMB’s main cost arises from repeated conditional independence tests, parallel or distributed strategies can alleviate runtime issues in large datasets if computing resources permit.  

────────────────────────────────────────────────────────
3. Mixed Data & Complex Functions
────────────────────────────────────────────────────────

• Noise Type  
  – InterIAMB itself does not strictly assume Gaussian noise; rather, the performance depends on the independence tests. If the user chooses “fisherz,” a linear-Gaussian assumption is made. For more general or non-Gaussian data, tests like “kci” or “rcit” allow detecting more complex dependencies.  

• Mixed Data (Continuous & Discrete)  
  – The algorithm can accommodate both types of variables by selecting, for instance, “gsq” or other specialized tests. The recommended practice is to carefully match data types to an appropriate test method so that the underlying assumptions are not violated.  

• Heterogeneous Data  
  – Benchmarks reflect moderate performance for heterogeneous datasets (e.g., multiple types of variables). InterIAMB can handle such data if the independence test is chosen appropriately, but advanced scenarios (massive amounts of unbalanced continuous/discrete variables) might require more carefully tuned hyperparameters or specialized tests.  

• Complex Functional Forms  
  – In principle, InterIAMB can uncover non-linear associations if a corresponding non-linear independence test is used. However, if a purely linear test (“fisherz”) is chosen, strong non-linear relationships may be missed or misinterpreted.  

• Critique/Extension  
  – As a constraint-based method, InterIAMB does not inherently model functional forms; it relies on the independence test’s ability to detect conditional dependencies. To capture very complex relationships, users are advised to select robust non-linear tests (e.g., “kci,” “rcit”).  

────────────────────────────────────────────────────────
4. Computational Complexity
────────────────────────────────────────────────────────

• Theoretical Time Complexity  
  – The complexity is often cited as <temp>[O(n^2)]</temp> in many references, though in practice it can grow faster if repeated independence tests become more extensive for large n or for complex network structures.  

• Variability in Practical Usage  
  – Increasing the number of variables or choosing more computationally heavy tests (e.g., kernel-based ones) can significantly expand runtime. Tighter α thresholds can also add overhead by requiring additional checks to confirm or reject a conditional independence.  
  – In benchmarks, InterIAMB was not the slowest method tested but does experience performance degradation with many variables and repeated conditional testing.  

• Critique/Extension  
  – InterIAMB’s worst-case behavior can be higher than the quoted O(n^2) depending on the network’s connectivity and iterative test expansions. Typical implementations, however, are optimized for average-case performance.  
  – Modern computing platforms (multi-core, GPU) can reduce bottlenecks if code is parallelized for independence tests.  

────────────────────────────────────────────────────────
5. Interpretability
────────────────────────────────────────────────────────

• Output Format  
  – Rather than outputting a full causal structure (like a DAG), InterIAMB focuses on the Markov blanket for each target variable: the minimal set of variables that shield the target from all other variables.  

• Strength of the Output Format  
  – The Markov blanket is highly interpretable: users see exactly which variables are directly relevant (parents, children, and co-parents) to a target. This can be ideal for feature selection or local neighborhood discovery in a causal sense.  

• Limitations of the Output Format  
  – The direction or orientation of edges is not inherently guaranteed. Thus, while InterIAMB indicates local dependencies, it does not by itself fully resolve causal directions or detect hidden confounders.  
  – Confidence metrics or p-values for edges can be parsed from the conditional independence tests, but are not always aggregated in a single “score.”  

• Critique/Extension  
  – For broader causal conclusions, many users combine InterIAMB with a separate orientation step (e.g., a scoring-based method or domain-expert input). This pipeline approach often yields improved interpretability of causal relations.  

────────────────────────────────────────────────────────
6. Assumptions
────────────────────────────────────────────────────────

• Critical Assumptions  
  – Causal Sufficiency: No significant latent confounders that connect variables in unobserved ways.  
  – Markov Condition: Each variable is conditionally independent of its non-descendants given its parents.  
  – Faithfulness (or “No cancellations”): The observed independencies in the data reflect the true underlying causal structure.  

• Violation Impact  
  – Violating causal sufficiency or faithfulness can degrade correctness of the discovered MB. This might result in missing edges or spurious associations if hidden confounders violate these assumptions.  
  – In some community-reported evaluations, small omissions to faithfulness did not drastically degrade InterIAMB, but major violations (e.g., strong confounding) caused significant inaccuracies.  

• Critique/Extension  
  – Certain InterIAMB variants relax these assumptions partially, but the standard InterIAMB remains a constraint-based approach relying heavily on them. Users encountering potential hidden confounding often resort to domain knowledge or extended algorithms for adjustments.  

────────────────────────────────────────────────────────
7. (Optional) Real-World Benchmarks
────────────────────────────────────────────────────────

• Performance on Real Datasets  
  – InterIAMB has performed competitively in several MB discovery benchmarks, frequently matching or outperforming earlier IAMB variants. In moderately sized real-world datasets, it often demonstrates a good balance between precision (avoiding false edges) and recall (identifying true associations).  
  – Compared to specialized high-dimensional methods, InterIAMB can be outpaced when the number of variables becomes extremely large, but remains quite practical for many standard real-world settings.  

• Practical Tips  
  – Combining InterIAMB with a subsequent orientation step or domain expertise is often recommended to interpret directions.  
  – Users handling data with highly non-linear relationships frequently choose a kernel-based, non-linear independence test.  
  – Missing data remain a common pitfall; pre-processing or specialized tests can alleviate performance dips.  

────────────────────────────────────────────────────────
Final Remarks
────────────────────────────────────────────────────────
InterIAMB is a notable variant of the IAMB family, offering iterative refinements that often improve speed and accuracy over the original. Its main hyperparameter, α, is easy to tune based on data size, and its flexible independence test options allow it to handle various data types or noise structures. The algorithm works well for moderate-dimensional problems and moderate levels of missing or noisy data, especially if paired with robust tests and parallel computing resources. However, it does not natively provide edge orientations or handle severe assumption violations, so further post-processing or hybrid approaches may be required for complete causal insights.

────────────────────────────────────────────────────────
Benchmarking Results
────────────────────────────────────────────────────────

• Comparative Performance
  – The benchmarking compared 19 different causal discovery algorithms across multiple scenarios.
  – Each algorithm was evaluated on performance (accuracy), efficiency (runtime), and composite metrics, which are represented as level scores from 1-5, with 5 being the best.
  – Levels scores of composite metrics combine performance and efficiency (weights: 0.8 and 0.2 respectively).
[NOTE] The ranking is smaller, the better. The level score is higher, the better.

• Algorithm Rankings

| Scenario | Rank (Mean) | Rank (Std Dev) | Performance (Level) | Efficiency (Level) | Composite (Level) |
|----------|-----------|---------|-------------|------------|------------|
| Scalability | 5.4 | 1.73 | 4.0 | 4.0 | 4.0 |
| Heterogeneity | 3.2 | 1.09 | 5.0 | 3.0 | 5.0 |
| Measurement Error | 5.0 | 0.00 | 4.0 | 3.0 | 4.0 |
| Noise Type | 6.0 | 1.00 | 4.0 | 3.0 | 4.0 |
| Missing Data | 2.2 | 1.64 | 5.0 | 3.0 | 5.0 |
| Edge Probability | 6.3 | 2.62 | 4.0 | 3.0 | 4.0 |
| Discrete Ratio | 5.0 | 0.00 | 4.0 | 3.0 | 4.0 |

• Analysis

  – Overall mean ranking across 7 scenarios: 4.74
  – Average standard deviation: 1.15



## Supported hyperparameters: {
    "algorithm_name": "InterIAMB",
    "alpha": {
        "meaning": "Desired significance level in (0, 1)",
        "available_values": {
            "default": 0.05,
            "small_sample": 0.1,
            "large_sample": 0.01
        },
        "expert_suggestion": "Adjust based on sample size, more conservative (lower) values for larger samples. If < 500, use 0.1; Else if 500-10000 (<10000 but >500), use 0.05; Else if > 10000, using 0.01."
    },
    "indep_test": {
        "meaning": "Independence test method",
        "available_values": {
            "default": "fisherz",
            "continuous": "fisherz",
            "discrete": "chisq",
            "robust_nonlinear": "kci",
            "fast_robust_nonlinear": "fastkci",
            "approximate_fast_nonlinear": "rcit"
        },
        "expert_suggestion": "Choose based on data type, 'fisherz' for linear continuous data; 'chisq' for discrete data (only applied for pure discrete data); 'kci' for nonlinear data (very slow, use only with variable size < 15 and sample size < 1500); 'fastkci' is faster than kci (use with < 20 variables and sample size < 3000); 'rcit' is the fastest approximation of kci (use with < 30 variables and sample size < 5000)."
    }
}

======================================

# IAMBnPC

Below is a comprehensive seven-dimensional profile of the IAMBnPC algorithm, integrating the provided hyperparameter specifications, benchmarking statistics, and external/archival information about how this algorithm operates in practice.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
1. Hyper-Parameters Sensitivity
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Number of Key Hyperparameters  
  - Based on the provided hyperparameter dictionary (File #1) and external sources (File #3), IAMBnPC has two primary hyperparameters that most strongly affect results:  
    1) α (alpha), the significance level for independence testing.  
    2) The independence test selection (indep_test), which can vary (fisherz, chisq, etc.) depending on data type.  
  - Some implementations also expose a “max.sx” parameter (often described in community documentation and academic references) that controls the maximum conditioning set size, which can be crucial in higher-dimensional setups.

• Tuning Difficulty  
  - The significance level (alpha) has suggested defaults (e.g., 0.05 for moderate samples, 0.1 for smaller, 0.01 for very large samples) (File #1). These guidelines simplify tuning for standard use cases, but domain sense or iterative experimentation is beneficial for optimal results.  
  - The independence test parameter (indep_test) has clear default recommendations (fisherz for continuous data, chisq for discrete, etc.). In practice, a domain expert or an automated tool can select tests effectively once the data types (continuous, discrete, or mixed) and anticipated nonlinearities are identified.  
  - max.sx requires more advanced tuning as it directly influences computational effort and can demand deeper domain knowledge to avoid overly large conditioning sets.

• Sensitivity  
  - Small changes in alpha can noticeably alter the sparsity of the discovered structure: lowering alpha (e.g., from 0.05 to 0.01) typically yields fewer edges, while raising it runs the risk of extra false positives.  
  - Switching from a linear independence test (e.g., fisherz) to a nonlinear test (e.g., kci) can significantly extend runtime but often improves detection of complex relationships. Benchmarks (File #2) show that more robust or nonlinear tests can bring moderate decreases in efficiency but may help maintain performance under complex data conditions.

• Critique/Extension  
  - Parameters like alpha relate primarily to statistical tests, determining how conservative or permissive the algorithm is in drawing edges.  
  - By contrast, parameters such as max.sx or the choice of test method can have a major bearing on computational complexity in the graph-search phase. Tuning each in tandem is key to balancing runtime and accuracy.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
2. Robustness & Scalability
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Tolerance to Bad Data Quality  
  - Missing Data: IAMBnPC does not have a specialized built-in mechanism for handling missingness; most implementations rely on either casewise deletion or test-specific adjustments. According to benchmark observations (File #2), the algorithm’s performance in scenarios with moderate missing data typically remains acceptable, but more severe missingness can degrade inference reliability.  
  - Measurement/Observation Error: Benchmark statistics (File #2) suggest the algorithm ranks around the middle-to-lower range when measurement error is severe, indicating sensitivity to inaccuracies in the independence tests.

• Tolerance to Sparse/Dense Connected Systems  
  - Sparse Graphs: IAMBnPC often excels in sparse settings because fewer edges reduce the conditioning set searches, making it easier to identify Markov Blankets accurately.  
  - Dense Graphs: As density grows, the algorithm’s computational load can increase. It generally still performs competitively if the sample size is sufficient, but it may be slower in identifying all relevant edges accurately.

• Scalability  
  - Benchmarks (File #2) show that under moderate problem sizes, IAMBnPC scales adequately, though it does not always place at the top in efficiency.  
  - Very large numbers of variables or extremely large sample sizes can stress runtime, especially if max.sx or more complex tests (e.g., kci) are used. Memory usage can also become a bottleneck, but partial parallelization of independence tests may mitigate some performance issues.

• Critique/Extension  
  - Parallelization strategies for the independence tests can help handle large data sets faster, an approach mentioned in community discussions (File #3).  
  - Some extensions implement approximate tests or heuristic-based constraint pruning to better cope with large or noisy data environments.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
3. Mixed Data & Complex Functions
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Noise Type  
  - IAMBnPC does not strictly require Gaussian noise; it adopts whichever independence test is chosen (File #1). This flexibility allows for non-Gaussian or even nonparametric tests (e.g., kci), albeit at added computational cost.

• Mixed Data (Continuous & Discrete)  
  - As per File #1, the suggested test for discrete variables is chisq, and for mixed variables, gsq or other methods (gsq, kci in certain hybrid contexts). This indicates built-in support for analyzing mixed data types, as long as the user selects an appropriate test.

• Heterogeneous Data  
  - Benchmarks (File #2) show moderate reliability when data are heterogeneous (the algorithm’s ranking is neither the highest nor the lowest in that regard). Much depends on how well the chosen test handles distribution shifts and varied variable types.

• Complex Functional Forms  
  - If a nonlinear independence test (like kci) is selected (File #1), IAMBnPC can detect non-linear relationships. Default linear tests (e.g., fisherz) work well but may miss intricate dependencies.

• Critique/Extension  
  - By default, many IAMBnPC implementations use parametric tests (fisherz or chisq) that assume linear or categorical relationships. Users dealing with strongly nonlinear phenomena might consider kci or rcit for better detection, though these methods require more computational time and possibly larger sample sizes to remain stable.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
4. Computational Complexity
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Theoretical Time Complexity  
  - <temp>[O(|MB(T)| × N)]</temp>, where |MB(T)| is the size of the Markov Blanket of the target T, and N is the overall number of variables. In practice, this can vary if the algorithm iterates repeatedly to refine the Markov Blanket.

• Variability in Practical Usage  
  - Increased max.sx or using more complex independence tests can increase runtime considerably.  
  - Benchmark data (File #2) suggest that IAMBnPC tends to occupy a moderate position in efficiency: not the fastest for extremely large networks, but still viable for typical mid-to-large-scale scenarios.

• Critique/Extension  
  - Real-world usage indicates that worst-case performance rises if the underlying Markov Blanket includes many variables, making the search space large.  
  - Some open-source implementations can leverage multi-core systems to test multiple candidates in parallel, improving real-world runtime.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
5. Interpretability
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Output Format  
  - IAMBnPC typically identifies a Markov Blanket for a target variable, which includes parents, children, and parents of children (spouses). In more extended usage, it can be used sequentially for each variable, approximating a larger causal structure in the form of adjacency lists or adjacency matrices.

• Strength of the Output Format  
  - Markov blankets are highly interpretable, especially in domain-focused tasks (e.g., finding key predictors). Some implementations provide conditional independence p-values, adding numeric confidence to the adjacency information.

• Limitations of the Output Format  
  - By design, Markov Blanket discovery alone does not fully orient all edges (e.g., distinguishing the parent from the child can require an additional causal orientation step or a separate backward phase).  
  - If sample size is small or alpha is too lenient, false positives may appear in the Markov Blanket, reducing clarity.

• Critique/Extension  
  - Domain experts often post-process the discovered Markov Blankets (e.g., verifying directions or removing improbable edges).  
  - Community resources (File #3) recommend cross-referencing these results with domain constraints for added orientation confidence.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
6. Assumptions
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Critical Assumptions  
  - Markov Condition: The causal structure in question encodes all conditional independencies present in the data.  
  - Faithfulness: All and only the independencies found in the data are represented in the graph (File #3).  
  - Causal Sufficiency: No unmeasured confounding variables relevant to the included variables.

• Violation Impact  
  - Failure of faithfulness (e.g., strong cancellations or nonlinear confounding) can lead to spurious or missing edges.  
  - Hidden confounders (violating causal sufficiency) may result in flawed Markov Blanket identification.

• Critique/Extension  
  - Some advanced variations relax faithfulness assumptions, allowing for approximate independence detection.  
  - In presence of suspected hidden variables, a user might need to adopt extended methods (e.g., latent variable detection) or adopt additional domain knowledge to correct for confounders.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
7. (Optional) Real-World Benchmarks
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Performance on Real Datasets  
  - While synthetic experiments provide clarity on alpha’s influence and Markov Blanket sizes, real-world comparisons usually find IAMBnPC near or somewhat above middle-tier performance in terms of both accuracy and runtime (File #2).  
  - In bioinformatics (e.g., gene regulatory networks), IAMBnPC is often praised for effectively identifying candidate regulators for a given gene.

• Practical Tips  
  - Employ domain knowledge whenever possible to set alpha and refine conditioning sets. This often curbs false positives in the Markov Blanket.  
  - If data are high-dimensional or heavily nonlinear, consider advanced (nonlinear) tests and parallelization where available.  
  - Users should be mindful of the assumptions (faithfulness, causal sufficiency), as real-world violations can degrade reliability. Complementing IAMBnPC with domain-specific heuristics or knowledge can help avert misinterpretation.

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Summary
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
IAMBnPC is a Markov Blanket discovery algorithm that integrates the iterative conditional independence testing strategy of IAMB with backward-phase refinements inspired by the PC algorithm. Its primary hyperparameter (alpha) controls the strictness of conditional independence tests; tuning this in conjunction with the independence test choice (e.g., fisherz, chisq, kci) is crucial. Though generally robust and interpretable, its performance can diminish with high data noise, missingness, or unfaithful structures. Parallelization or approximate testing can improve scalability, and domain knowledge often helps prune extraneous edges and increase interpretability. Overall, IAMBnPC is a solid and often competitive choice for applications—especially those where identifying relevant predictors for a target variable is paramount—provided its underlying assumptions align reasonably well with the data-generating process.

────────────────────────────────────────────────────────
Benchmarking Results
────────────────────────────────────────────────────────

• Comparative Performance
  – The benchmarking compared 19 different causal discovery algorithms across multiple scenarios.
  – Each algorithm was evaluated on performance (accuracy), efficiency (runtime), and composite metrics, which are represented as level scores from 1-5, with 5 being the best.
  – Levels scores of composite metrics combine performance and efficiency (weights: 0.8 and 0.2 respectively).
[NOTE] The ranking is smaller, the better. The level score is higher, the better.

• Algorithm Rankings

| Scenario | Rank (Mean) | Rank (Std Dev) | Performance (Level) | Efficiency (Level) | Composite (Level) |
|----------|-----------|---------|-------------|------------|------------|
| Scalability | 7.4 | 3.90 | 4.0 | 3.0 | 4.0 |
| Heterogeneity | 3.5 | 2.69 | 4.0 | 5.0 | 5.0 |
| Measurement Error | 6.8 | 0.83 | 3.0 | 5.0 | 4.0 |
| Noise Type | 8.5 | 0.50 | 3.0 | 5.0 | 3.0 |
| Missing Data | 3.8 | 2.49 | 5.0 | 3.0 | 5.0 |
| Edge Probability | 6.0 | 1.41 | 4.0 | 5.0 | 4.0 |
| Discrete Ratio | 6.7 | 0.94 | 4.0 | 5.0 | 4.0 |

• Analysis

  – Overall mean ranking across 7 scenarios: 6.08
  – Average standard deviation: 1.82



## Supported hyperparameters: {
    "algorithm_name": "IAMBnPC",
    "alpha": {
        "meaning": "Desired significance level in (0, 1)",
        "available_values": {
            "default": 0.05,
            "small_sample": 0.1,
            "large_sample": 0.01
        },
        "expert_suggestion": "Adjust based on sample size, more conservative (lower) values for larger samples. If < 500, use 0.1; Else if 500-10000 (<10000 but >500), use 0.05; Else if > 10000, using 0.01."
    },
    "indep_test": {
        "meaning": "Independence test method",
        "available_values": {
            "default": "fisherz",
            "continuous": "fisherz",
            "discrete": "chisq",
            "robust_nonlinear": "kci",
            "fast_robust_nonlinear": "fastkci",
            "approximate_fast_nonlinear": "rcit"
        },
        "expert_suggestion": "Choose based on data type, 'fisherz' for linear continuous data; 'chisq' for discrete data (only applied for pure discrete data); 'kci' for nonlinear data (very slow, use only with variable size < 15 and sample size < 1500); 'fastkci' is faster than kci (use with < 20 variables and sample size < 3000); 'rcit' is the fastest approximation of kci (use with < 30 variables and sample size < 5000)."
    }
}



===============================================

Think in-depth and thoroughly step by step. Please include the reasoning process, the ultimate reason why the picked algorithm beats the others and finally the selected algorithm in the JSON format. Cite/Quote quantity/number and references for the evidences of analyzing using one specific algorithm or not. Do not return any other text or comments:

{
  "reasoning": "reasoning process",
  "reason": "ultimate reason why it beats the others"
  "algorithm": "algorithm_name",
}
