### CORL (Causal discovery with Ordering-based Reinforcement Learning)

- **Description**: A reinforcement learning based algorithm that discovers causal structure by learning to find the optimal ordering of variables. It uses actor-critic architecture with either episodic or dense rewards.

- **Assumptions**
    - **Acyclicity**: The underlying causal structure is acyclic (DAG)
    - **Faithfulness**: The observed statistical dependencies reflect the true causal structure
    - **No Hidden Confounders**: All relevant variables are observed
    - **Sufficient Data**: Requires enough samples to learn meaningful patterns

- **Advantages**
    - Scalable to large graphs due to the ordering-based approach
    - Can handle both linear and non-linear relationships
    - More efficient than previous RL-based approaches
    - Two reward modes (episodic and dense) for different scenarios

- **Limitations**
    - Training can be computationally intensive
    - Performance depends on hyperparameter tuning
    - May require GPU for larger graphs
    - Stochastic nature of RL can lead to varying results

- **Suitable Cases**:
    - Large-scale causal discovery problems
    - When computational resources (especially GPU) are available
    - When the underlying relationships could be non-linear
    - When traditional constraint or score-based methods struggle 