# Causal Discovery Algorithm Tagging

## Performance Categories (Consistent Across All Tags)
- **Robust**: Consistently strong performance (â‰¥80% accuracy) across multiple scenarios with low variability
- **Strong**: Good performance (60-80% accuracy) with moderate variability across scenarios  
- **Moderate**: Generally reliable performance (40-60% accuracy) with moderate to high variability
- **Limited**: Weaker performance (<40% accuracy) with significant variability
- **Poor**: Unreliable performance or high variability across most scenarios

## Algorithm Tag Categories

1. **Availability**: Available, Unavailable

2. **Method Type**: Constraint-based, Score-based, Functional Model-based, Hybrid, MB-based, Continuous-optimization

3. **Functional Form**: 
   - Linear: Optimized for linear relationships
   - Nonlinear: Optimized for non-linear relationships
   - Flexible: Handles both linear and non-linear relationships effectively

4. **Noise**: 
   - Gaussian: Performance drops with non-Gaussian noise
   - NonGaussian: Performance improves with non-Gaussian noise
   - Flexible: Similar performance between Gaussian and non-Gaussian noise

5. **Latent Variable Tolerance**: 
   - Robust: Maintains high performance with latent variables
   - Moderate: Maintains moderate performance with latent variables

6. **Distribution Shift**: 
   - Heterogenous: Maintains high performance under heterogeneity
   - Homogenous: Performance drops under heterogeneity

7. **Scalability**: 
   - Large-scale: Handles >100 variables efficiently
   - Medium-to-large-scale: Handles 50-100 variables efficiently
   - Medium-scale: Handles 20-50 variables efficiently
   - Small-to-medium-scale: Handles 10-20 variables efficiently
   - Small-scale: Limited to <10 variables

8. **Efficiency**: 
   - Extreme Fast (GPU): Very short runtime (<1 min) per 1000 samples with 50 variables
   - Fast (GPU): Short runtime (1-5 min) per 1000 samples with 50 variables
   - Fast (CPU): Reasonable runtime (5-15 min) per 1000 samples with 50 variables
   - Moderate: Medium runtime (15-60 min) per 1000 samples with 50 variables
   - Slow: Long runtime (1-4 hours) per 1000 samples with 50 variables
   - Extreme Slow: Very long runtime (>4 hours) per 1000 samples with 50 variables

9. **Empirical Performance**: Based on overall benchmark score
   - Robust: High overall score
   - Strong: Good overall score
   - Moderate: Average overall score
   - Limited: Below average overall score
   - Poor: Low overall score

10. **Output Format**: DAG, CPDAG, PAG

11. **Data Type**: Tabular, Time-series, Both

12. **Graph Density Preference**:
   - Sparse-Preferring: Algorithm performs significantly better on sparse graphs
   - Dense-Preferring: Algorithm performs significantly better on dense graphs
   - Density-Robust: Algorithm maintains consistent performance across different graph densities

## Algorithm Listings (key are the algorithm names)

### Constraint-based Methods

PC: {
    Full Name: "Peter-Clark Algorithm",
    Availability: Available,
    Method Type: Constraint-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale with default settings, can scale to large datasets (thousands of variables) with GPU acceleration,
    Efficiency: Fast with CPU, Extreme Fast with GPU acceleration,
    Empirical Performance: Strong,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

FCI: {
    Full Name: "Fast Causal Inference",
    Availability: Available,
    Method Type: Constraint-based,
    Functional Form: Flexible, 
    Noise: Flexible,
    Latent Variable Tolerance: Robust,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Fast (CPU),
    Empirical Performance: Robust,
    Output Format: PAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

CDNOD: {
    Full Name: "Constraint-based causal Discovery from Nonstationary/heterogeneous Data",
    Availability: Available,
    Method Type: Constraint-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Scalability: Medium-to-large-scale with default settings, can scale to large datasets (thousands of variables) with GPU acceleration,
    Efficiency: Fast with CPU, Extreme Fast with GPU acceleration,
    Empirical Performance: Strong,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring,
    Note: "Requires heterogeneity in data with explicit domain_index column indicating different environments/domains",
    Distribution Shift: Heterogeneous
}

PCMCI: {
    Full Name: "Peter and Clark algorithm with Momentary Conditional Independence",
    Availability: Available,
    Method Type: Constraint-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Fast,
    Empirical Performance: Strong,
    Output Format: DAG,
    Data Type: Time-series,
    Graph Density Preference: Sparse-Preferring
}

### MB-based Methods

InterIAMB: {
    Full Name: "Interleaved Incremental Association Markov Blanket",
    Availability: Available,
    Method Type: MB-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Fast,
    Empirical Performance: Limited,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

BAMB: {
    Full Name: "Bootstrap Augmented Markov Blanket",
    Availability: Available,
    Method Type: MB-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Robust,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Limited,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

HITONMB: {
    Full Name: "HITON Markov Blanket",
    Availability: Unavailable,
    Method Type: MB-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Limited,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

IAMBnPC: {
    Full Name: "Incremental Association Markov Blanket with PC algorithm",
    Availability: Available,
    Method Type: Hybrid,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Fast,
    Empirical Performance: Robust,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

MBOR: {
    Full Name: "Markov Blanket OR",
    Availability: Available,
    Method Type: MB-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Limited,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

### Score-based Methods

GES: {
    Full Name: "Greedy Equivalence Search",
    Availability: Available,
    Method Type: Score-based,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Strong,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

FGES: {
    Full Name: "Fast Greedy Equivalence Search",
    Availability: Available,
    Method Type: Score-based,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Large-scale,
    Efficiency: Extreme Fast (CPU),
    Empirical Performance: Strong,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

XGES: {
    Full Name: "eXtremely Greedy Equivalence Search",
    Availability: Available,
    Method Type: Score-based,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Fast (CPU),
    Empirical Performance: Robust,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

GRaSP: {
    Full Name: "Greedy Relaxations of the Sparsest Permutation",
    Availability: Available,
    Method Type: Score-based,
    Functional Form: Flexible,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Robust,
    Output Format: CPDAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}

### Continuous-optimization Methods

GOLEM: {
    Full Name: "Gradient-based Optimization of dag-penalized Likelihood for learning linEar dag Models",
    Availability: Available,
    Method Type: Continuous-optimization,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale,
    Efficiency: Slow,
    Empirical Performance: Robust,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Density-Robust
}

CALM: {
    Full Name: "Causal Additive Linear Model",
    Availability: Unavailable,
    Method Type: Continuous-optimization,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Small-scale,
    Efficiency: Extreme Slow,
    Empirical Performance: Moderate,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Density-Robust
}

CORL: {
    Full Name: "Causal discovery with Ordering-based Reinforcement Learning",
    Availability: Unavailable,
    Method Type: Continuous-optimization,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Small-scale,
    Efficiency: Extreme Slow,
    Empirical Performance: Moderate,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Density-Robust
}

NOTEARSLinear: {
    Full Name: "Nonlinear Optimization with Trace Exponential and Augmented lagRangian for Structure learning (Linear)",
    Availability: Available,
    Method Type: Continuous-optimization,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Robust,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Density-Robust
}

NOTEARSNonlinear: {
    Full Name: "Nonlinear Optimization with Trace Exponential and Augmented lagRangian for Structure learning (Nonlinear)",
    Availability: Unavailable,
    Method Type: Continuous-optimization,
    Functional Form: Nonlinear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Slow,
    Empirical Performance: Moderate,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Density-Robust
}

DYNOTEARS: {
    Full Name: "Dynamic Nonlinear Optimization with Trace Exponential and Augmented lagRangian for Structure learning",
    Availability: Available,
    Method Type: Continuous-optimization,
    Functional Form: Linear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Strong,
    Output Format: DAG,
    Data Type: Time-series,
    Graph Density Preference: Sparse-Preferring
}

NTSNOTEARS: {
    Full Name: "Non-linear Time Series Nonlinear Optimization with Trace Exponential and Augmented lagRangian for Structure learning",
    Availability: Available,
    Method Type: Continuous-optimization,
    Functional Form: Nonlinear,
    Noise: Flexible,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Moderate,
    Empirical Performance: Strong,
    Output Format: DAG,
    Data Type: Time-series,
    Graph Density Preference: Sparse-Preferring
}

### Functional Model-based Methods (LiNGAM Family)

DirectLiNGAM: {
    Full Name: "Direct Linear Non-Gaussian Acyclic Model",
    Availability: Available,
    Method Type: Functional Model-based,
    Functional Form: Linear,
    Noise: NonGaussian,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale with default settings, can scale to large datasets with GPU acceleration,
    Efficiency: Fast with CPU, Faster with GPU acceleration,
    Empirical Performance: Limited,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Dense-Preferring,
    Note: "A MUST try on linear non-Gaussian data but poor on Gaussian noise, explaining the overall Limited empirical performance"
}

ICALiNGAM: {
    Full Name: "Independent Component Analysis Linear Non-Gaussian Acyclic Model",
    Availability: Unavailable,
    Method Type: Functional Model-based,
    Functional Form: Linear,
    Noise: NonGaussian,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Small-scale,
    Efficiency: Slow,
    Empirical Performance: Limited,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Dense-Preferring
}

VARLiNGAM: {
    Full Name: "Vector Autoregressive Linear Non-Gaussian Acyclic Model",
    Availability: Available,
    Method Type: Functional Model-based,
    Functional Form: Linear,
    Noise: NonGaussian,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-to-large-scale with default settings, can scale to large datasets with GPU acceleration,
    Efficiency: Fast with CPU, Faster with GPU acceleration,
    Empirical Performance: Strong,
    Output Format: DAG,
    Data Type: Time-series,
    Graph Density Preference: Dense-Preferring
}

### Hybrid Methods

GrangerCausality: {
    Full Name: "Granger Causality",
    Availability: Available,
    Method Type: Hybrid,
    Functional Form: Linear,
    Noise: Gaussian,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Medium-scale,
    Efficiency: Fast,
    Empirical Performance: Moderate,
    Output Format: DAG,
    Data Type: Time-series,
    Graph Density Preference: Sparse-Preferring
}

Hybrid: {
    Full Name: "Hybrid Causal Structure Learning",
    Availability: Unavailable,
    Method Type: Hybrid,
    Functional Form: Flexible,
    Noise: Gaussian,
    Latent Variable Tolerance: Moderate,
    Distribution Shift: Homogenous,
    Scalability: Small-scale,
    Efficiency: Slow,
    Empirical Performance: Moderate,
    Output Format: DAG,
    Data Type: Tabular,
    Graph Density Preference: Sparse-Preferring
}
