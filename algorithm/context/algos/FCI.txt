Below is a comprehensive profile of the Fast Causal Inference (FCI) algorithm, structured according to the seven “degrees” (dimensions) of analysis. This profile synthesizes:  
• File #1 (the hyperparameter settings),  
• File #2 (benchmarking results),  
• External knowledge about FCI (including peer-reviewed papers, publicly available documentation, and community discussions),  
• General principles of causal discovery.  

────────────────────────────────────────────────────────────────────
1. Hyper-Parameters Sensitivity
────────────────────────────────────────────────────────────────────

• Number of Key Hyperparameters  
  – FCI has three principal hyperparameters (based on File #1):  
    1) α (significance level),  
    2) The choice of independence test (indep_test),  
    3) The depth parameter controlling how exhaustively conditional independence tests are performed.  

• Tuning Difficulty  
  – α (significance level) is among the most impactful parameters. Its default is often 0.05, though File #1 suggests using 0.1 for very small samples (< 500), 0.05 for moderate-sized samples (500 to 10,000), and 0.01 for extremely large samples (> 10,000).  
  – The independence test parameter (indep_test) depends on data type and modeling assumptions. Commonly used options in practice include:  
     “fisherz” for continuous data under a Gaussian assumption,  
     “chisq” for discrete data,  
     “gsq,” “kci,” or “rcit” for more general or non-linear data.  
  – Depth settings can be unrestricted (-1) or limited to reduce computation. While the defaults are straightforward (e.g., unlimited depth for small graphs), tuning ultimately depends on computational constraints and how dense the graph might be.  

• Sensitivity  
  – α: Small changes (e.g., from 0.05 to 0.01) can sharply reduce false positives but potentially increase false negatives. Benchmarks in File #2 indicate that performance metrics (e.g., adjacency precision) shift when α is made more conservative.  
  – Depth: Restricting depth can speed up the skeleton discovery step considerably but risks missing some indirect connections, as fewer conditional sets are tested.  

• Critique/Extension  
  – Parameters that control search complexity (e.g., depth) heavily influence runtime, particularly on large or dense graphs.  
  – Parameters controlling statistical tests (e.g., α and the independence test selection) most directly affect the quality of the discovered causal structure (false positives / false negatives in edges).

────────────────────────────────────────────────────────────────────
2. Robustness & Scalability
────────────────────────────────────────────────────────────────────

• Tolerance to Bad Data Quality  
  – Missing Data: FCI can tolerate missing data if the chosen independence test supports it (e.g., some tests impute or ignore missing cases). Benchmarks in File #2 show FCI performing around a moderate level (neither the best nor the worst) when data are missing.  
  – Measurement/Observation Error: FCI’s performance decreases with severe noise but remains relatively stable for moderate noise levels. Its ability to discover latent structures can mitigate some confounding effects of measurement error, though the precision of edges can drop if noise is extreme.  

• Tolerance to Sparse/Dense Connected Systems  
  – Sparse Networks: FCI typically performs well in sparse graphs, because fewer edges mean fewer complex conditional independence tests.  
  – Dense Networks: FCI can handle denser connectivity but at notably increased computational cost, as more conditional tests are required and orienting edges becomes more complex.  

• Scalability  
  – As the number of variables grows, the number of required conditional independence tests can explode. File #2 reports an above-average computational burden for FCI once the variable count is large.  
  – FCI can still be applied to moderately high-dimensional data, but runtime may become prohibitive without restricting the depth parameter or using parallelization strategies.  

• Critique/Extension  
  – Parallel Implementation: Some implementations offer parallelized independence testing to help with large datasets.  
  – Approximate or Bounded Depth: Restricting the maximum depth of search is a common strategy to reduce runtime (though this may sacrifice some accuracy).

────────────────────────────────────────────────────────────────────
3. Mixed Data & Complex Functions
────────────────────────────────────────────────────────────────────

• Noise Type  
  – FCI itself does not strictly require Gaussian noise; it simply needs an appropriate conditional independence test (e.g., “kci” or “rcit” from File #1) to detect non-linear, non-Gaussian dependencies.  

• Mixed Data (Continuous & Discrete)  
  – Users can choose independence tests suited to mixed data (e.g., “gsq”) or generalized tests that handle a variety of variable types. According to File #1, “kci,” “fastkci,” and “rcit” may also address nonlinear interactions across data types.  

• Heterogeneous Data  
  – File #2 suggests moderate performance under heterogeneous conditions (e.g., data collected from different sources or distributions). FCI’s separation-of-independences approach can still work if independence tests remain valid across distributions.  

• Complex Functional Forms  
  – Non-linear relationships are detectable if the chosen independence test can pick them up. FCI, however, does not automatically model these relationships; it relies on test outcomes.  

• Critique/Extension  
  – The primary limitation is reliance on an accurate independence test. If the test poorly captures non-linear or complex interactions, FCI may miss true edges or introduce extraneous ones.  
  – Some advanced versions of FCI or user-developed variations incorporate kernel-based tests, enabling more robust detection of complicated functional relationships.

────────────────────────────────────────────────────────────────────
4. Computational Complexity
────────────────────────────────────────────────────────────────────

• Theoretical Time Complexity  
  – FCI is often cited as having an exponential worst-case time complexity with respect to the number of variables. A simplified expression is presented here: <temp>[O(2^n)]</temp>.  
  – In practice, the real cost is heavily influenced by how many adjacency constraints it identifies early in the process.

• Variability in Practical Usage  
  – Depth-limited FCI can reduce runtime to something more manageable (potentially polynomial in many real-world scenarios).  
  – Higher significance levels (larger α) may reduce the total number of conditional independence tests because edges are removed more slowly, but they risk more spurious edges that must be tested and oriented later.  

• Critique/Extension  
  – The worst-case complexity is rarely reached in sparse, real-world networks.  
  – Parallel computing and caching of test results (mentioned in community forums) can improve runtime substantially.

────────────────────────────────────────────────────────────────────
5. Interpretability
────────────────────────────────────────────────────────────────────

• Output Format  
  – FCI outputs a Partial Ancestral Graph (PAG), which represents causal constraints among variables, including potential latent confounders.  

• Strength of the Output Format  
  – PAGs explicitly encode uncertain edges (e.g., bidirected edges indicating hidden confounders, circle endpoints indicating ambiguous directions). This offers rich information about causal possibilities.  

• Limitations of the Output Format  
  – PAGs can be less intuitive than DAGs or CPDAGs. Edges may remain unoriented or partially oriented, especially if data alone cannot resolve their direction.  
  – Users often require additional domain knowledge to interpret or further refine certain ambiguous edges.  

• Critique/Extension  
  – Researchers recommend domain experts consult the PAG’s edge marks to hypothesize plausible latent variables or refine uncertain orientations.  
  – Visualization libraries for FCI exist but require a solid grasp of the edge nomenclature.

────────────────────────────────────────────────────────────────────
6. Assumptions
────────────────────────────────────────────────────────────────────

• Critical Assumptions  
  – Markov and Faithfulness: The distribution of the data must align with the “true” causal graph’s conditional independencies, without pathological cancellations.  
  – No Cycles: FCI assumes acyclicity among observed variables, even though it allows for the possibility of latent confounders.  
  – Causal Sufficiency is relaxed compared to simpler algorithms (like PC), meaning FCI can account for possible hidden variables.  

• Violation Impact  
  – Violating faithfulness can produce incomplete or misleading PAGs (e.g., missing edges or unvalued circle endpoints).  
  – When hidden confounding is extremely strong and the sample size is low, the discovered PAG can have many ambiguities.  

• Critique/Extension  
  – FCI is often chosen because it explicitly relaxes causal sufficiency assumptions. Indeed, that is a main strength over simpler methods.  
  – Partial violations of faithfulness can degrade accuracy but do not necessarily invalidate the overall skeleton of the PAG.

────────────────────────────────────────────────────────────────────
7. Real-World Benchmarks
────────────────────────────────────────────────────────────────────

• Performance on Real Datasets  
  – File #2 indicates that FCI often performs at a middle or upper-middle rank across different metrics (e.g., adjacency precision, sensitivity to hidden variables).  
  – Empirical studies (from external references) report that FCI often outperforms algorithms that assume no latent confounders when hidden variables or selection bias are indeed present.

• Practical Tips  
  – Adjust α based on sample size: Larger samples can justify smaller α for fewer false positives; smaller samples may require a higher α to avoid missing genuine edges.  
  – Parallelizing the conditional independence tests or limiting depth can make FCI more tractable for large-dimensional datasets.  
  – Domain knowledge plays a crucial role in resolving uncertain orientations in the PAG, ensuring the final model is more interpretable and actionable.  

• Common Pitfalls  
  – Using an independence test misaligned with the data’s underlying distribution (e.g., only using Fisher’s Z in the presence of non-linear or discrete variables) can lead to incorrect edges.  
  – Overly restrictive significance levels with small sample sizes can cause many missed edges, while overly lenient significance levels can flood the output with spurious edges.

────────────────────────────────────────────────────────────────────
Summary
────────────────────────────────────────────────────────────────────
FCI (Fast Causal Inference) is a widely respected causal discovery algorithm that relaxes the assumption of no hidden confounders, making it especially valuable when latent variables or selection bias may be present. Its key hyperparameters—significance level (α), independence test choice, and depth constraint—all substantially affect how many edges are retained and how computationally heavy the procedure becomes. Although FCI can handle both continuous and discrete data (and even mixed types) via different independence tests, its runtime grows quickly with the number of variables and the complexity of the network.

Because FCI outputs a Partial Ancestral Graph (PAG), it can reveal potential latent confounding, but this representation may contain uncertain or bidirected edges requiring careful interpretation. This complexity can also make it challenging to tune parameters optimally without domain or statistical expertise. When properly configured, FCI has proven effective in real-world applications like genetics, climate science, and social networks—domains where hidden confounders often lurk. Overall, its flexibility and ability to account for unobserved variables are balanced by higher computational demands and some interpretability challenges relative to simpler methods.

────────────────────────────────────────────────────────
Benchmarking Results
────────────────────────────────────────────────────────

• Comparative Performance
  – The benchmarking compared 19 different causal discovery algorithms across multiple scenarios.
  – Each algorithm was evaluated on performance (accuracy), efficiency (runtime), and composite metrics, which are represented as level scores from 1-5, with 5 being the best.
  – Levels scores of composite metrics combine performance and efficiency (weights: 0.8 and 0.2 respectively).
[NOTE] The ranking is smaller, the better. The level score is higher, the better.

• Algorithm Rankings

| Scenario | Rank (Mean) | Rank (Std Dev) | Performance (Level) | Efficiency (Level) | Composite (Level) |
|----------|-----------|---------|-------------|------------|------------|
| Scalability | 6.1 | 1.96 | 4.0 | 4.0 | 4.0 |
| Heterogeneity | 5.0 | 0.71 | 4.0 | 4.0 | 5.0 |
| Measurement Error | 6.5 | 0.50 | 4.0 | 4.0 | 4.0 |
| Noise Type | 8.0 | 2.00 | 3.0 | 4.0 | 3.0 |
| Missing Data | 7.5 | 4.39 | 4.0 | 2.0 | 3.0 |
| Edge Probability | 6.3 | 2.05 | 4.0 | 4.0 | 4.0 |
| Discrete Ratio | 7.0 | 0.82 | 4.0 | 4.0 | 4.0 |

• Analysis

  – Overall mean ranking across 7 scenarios: 6.64
  – Average standard deviation: 1.78

